# SoundDitectApp

1D CNNモデルを使用したリアルタイム音声録音・分類のStreamlitウェブアプリケーションです。

## 機能

- **リアルタイム音声録音**: `streamlit-webrtc`を使用してブラウザからマイク音声をキャプチャ
- **1D CNN分類**: 音声セグメントを1秒ごとにOK (0) またはNG (1) として分類
- **音声処理**: 音声前処理を自動処理（22050 Hzサンプリング、モノラル変換、長さ正規化）
- **可視化**: 時間領域波形グラフに色分けされたセグメントで結果を表示
- **モデルサポート**: 事前学習済みPyTorchモデル（.pthファイル）の読み込み

## インストール

1. リポジトリをクローン:
```bash
git clone https://github.com/Kalorie560/SoundDitectApp.git
cd SoundDitectApp
```

2. 依存関係をインストール:
```bash
pip install -r requirements.txt
```

## 使用方法

1. Streamlitアプリを実行:
```bash
streamlit run app.py
```

2. サイドバーを使用して学習済みモデル（.pthファイル）をアップロード

3. 「Start」をクリックして音声録音を開始

4. マイクに向かって話す - アプリは1秒ごとのチャンクをリアルタイムで処理

5. 「Stop」をクリックして録音を終了し、結果を表示

## モデル要件

アプリケーションは以下の仕様のPyTorchモデルを想定しています：

- **入力形状**: `(batch_size, channels, length) = (1, 1, 22050)`
- **出力**: 二値分類（2クラス: OK=0, NG=1）
- **アーキテクチャ**: `nn.Conv1d`レイヤーを使用した1D CNN
- **音声フォーマット**: 22050 Hzサンプリングレート、モノラルチャンネル、1秒セグメント

## 音声処理

アプリは以下を自動で処理します：
- 22050 Hzへのリサンプリング
- モノラル変換（ステレオ入力の場合）
- 長さ正規化（22050サンプルへのパディングまたは切り詰め）
- 1秒セグメントへのリアルタイムチャンク分割

## 結果の可視化

録音後、アプリは以下を表示します：
- 色分けされた背景の音声波形プロット
- 緑のセグメント: OK分類
- 赤のセグメント: NG分類
- 要約統計（総持続時間、OK/NG数）
- 詳細な秒単位の結果

## 技術詳細

- StreamlitとStreamlit-webrtcで構築
- モデル推論にPyTorchを使用
- torchaudioとnumpyで音声処理
- matplotlibで可視化
- スレッドセーフな音声バッファリングと処理