import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torchaudio
import librosa
import sounddevice as sd
from pathlib import Path
import yaml
import time
import logging
from typing import Tuple, Optional
import warnings

# è­¦å‘Šã‚’æŠ‘åˆ¶
warnings.filterwarnings("ignore")

# Streamlitãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="éŸ³å£°æ¤œå‡ºã‚¢ãƒ—ãƒª",
    page_icon="ðŸŽµ",
    layout="wide"
)

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# config.yamlã‚’èª­ã¿è¾¼ã¿
@st.cache_resource
def load_config():
    try:
        with open('reference/config.yaml', 'r', encoding='utf-8') as f:
            return yaml.safe_load(f)
    except:
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'audio': {'sample_rate': 44100},
            'model': {'input_length': 44100, 'num_classes': 2}
        }

# éŸ³å£°ç•°å¸¸æ¤œçŸ¥ãƒ¢ãƒ‡ãƒ«ï¼ˆå‚è€ƒãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ç°¡ç•¥åŒ–ï¼‰
class SimpleAnomalyDetector(nn.Module):
    def __init__(self, input_length=44100, num_classes=2):
        super().__init__()
        
        # 1D CNN layers
        self.conv1 = nn.Conv1d(1, 32, kernel_size=256, stride=4)
        self.conv2 = nn.Conv1d(32, 64, kernel_size=128, stride=2)
        self.conv3 = nn.Conv1d(64, 128, kernel_size=64, stride=2)
        
        self.pool = nn.MaxPool1d(4)
        self.dropout = nn.Dropout(0.5)
        
        # FC layers
        self.fc1 = nn.Linear(self._get_conv_output_size(input_length), 256)
        self.fc2 = nn.Linear(256, num_classes)
        
    def _get_conv_output_size(self, input_length):
        # ç•³ã¿è¾¼ã¿å±¤ã®å‡ºåŠ›ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        x = torch.randn(1, 1, input_length)
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = self.pool(torch.relu(self.conv3(x)))
        return x.view(1, -1).size(1)
    
    def forward(self, x):
        # å…¥åŠ›ã¯ (batch_size, input_length)
        x = x.unsqueeze(1)  # (batch_size, 1, input_length)
        
        x = self.pool(torch.relu(self.conv1(x)))
        x = self.pool(torch.relu(self.conv2(x)))
        x = self.pool(torch.relu(self.conv3(x)))
        
        x = x.view(x.size(0), -1)
        x = self.dropout(torch.relu(self.fc1(x)))
        x = self.fc2(x)
        
        return x

# ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
@st.cache_resource
def load_model():
    config = load_config()
    model = SimpleAnomalyDetector(
        input_length=config['model']['input_length'],
        num_classes=config['model']['num_classes']
    )
    
    # è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿
    model_path = Path('models/best_model.pth')
    if model_path.exists():
        try:
            model.load_state_dict(torch.load(model_path, map_location='cpu'))
            logger.info("è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
        except:
            logger.warning("è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
    else:
        logger.info("è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¾ã™")
    
    model.eval()
    return model

# éŸ³å£°å‰å‡¦ç†
def preprocess_audio(audio_data, sample_rate=44100):
    # æ­£è¦åŒ–
    audio_data = audio_data.astype(np.float32)
    if np.max(np.abs(audio_data)) > 0:
        audio_data = audio_data / np.max(np.abs(audio_data))
    
    # 1ç§’é–“ï¼ˆ44100ã‚µãƒ³ãƒ—ãƒ«ï¼‰ã«èª¿æ•´
    if len(audio_data) > sample_rate:
        audio_data = audio_data[:sample_rate]
    elif len(audio_data) < sample_rate:
        audio_data = np.pad(audio_data, (0, sample_rate - len(audio_data)), mode='constant')
    
    return audio_data

# éŸ³å£°éŒ²éŸ³
def record_audio(duration_seconds, sample_rate=44100):
    st.info(f"ðŸŽ¤ {duration_seconds}ç§’é–“éŒ²éŸ³ä¸­...")
    
    try:
        # éŒ²éŸ³é–‹å§‹
        audio_data = sd.rec(int(duration_seconds * sample_rate), 
                           samplerate=sample_rate, 
                           channels=1, 
                           dtype='float32')
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
        progress_bar = st.progress(0)
        for i in range(int(duration_seconds * 10)):
            time.sleep(0.1)
            progress_bar.progress((i + 1) / (duration_seconds * 10))
        
        sd.wait()  # éŒ²éŸ³å®Œäº†ã¾ã§å¾…æ©Ÿ
        progress_bar.empty()
        
        return audio_data.flatten()
    
    except Exception as e:
        st.error(f"éŒ²éŸ³ã‚¨ãƒ©ãƒ¼: {e}")
        return None

# éŸ³å£°åˆ†æž
def analyze_audio(audio_data, model, sample_rate=44100):
    # 1ç§’æ¯Žã«åˆ†å‰²
    segments = []
    predictions = []
    confidences = []
    
    total_seconds = len(audio_data) // sample_rate
    
    for i in range(total_seconds):
        start_idx = i * sample_rate
        end_idx = start_idx + sample_rate
        segment = audio_data[start_idx:end_idx]
        
        # å‰å‡¦ç†
        processed_segment = preprocess_audio(segment, sample_rate)
        segments.append(processed_segment)
        
        # ãƒ¢ãƒ‡ãƒ«äºˆæ¸¬
        with torch.no_grad():
            input_tensor = torch.tensor(processed_segment).unsqueeze(0)
            output = model(input_tensor)
            probabilities = torch.softmax(output, dim=1)
            
            confidence, prediction = torch.max(probabilities, 1)
            predictions.append(prediction.item())
            confidences.append(confidence.item())
    
    return segments, predictions, confidences

# çµæžœãƒ—ãƒ­ãƒƒãƒˆ
def plot_results(audio_data, predictions, sample_rate=44100):
    fig, ax = plt.subplots(figsize=(15, 6))
    
    # æ™‚é–“è»¸
    time_axis = np.linspace(0, len(audio_data) / sample_rate, len(audio_data))
    
    # æ³¢å½¢ãƒ—ãƒ­ãƒƒãƒˆ
    ax.plot(time_axis, audio_data, color='blue', alpha=0.7, linewidth=0.5)
    
    # OK/NGåŒºé–“ã®èƒŒæ™¯è‰²
    for i, pred in enumerate(predictions):
        start_time = i
        end_time = i + 1
        color = 'lightgreen' if pred == 0 else 'lightcoral'
        label = 'OK' if pred == 0 else 'NG'
        
        ax.axvspan(start_time, end_time, alpha=0.3, color=color)
        
        # ä¸­å¤®ã«ãƒ©ãƒ™ãƒ«è¡¨ç¤º
        mid_time = start_time + 0.5
        ax.text(mid_time, max(audio_data) * 0.8, label, 
                ha='center', va='center', fontsize=12, fontweight='bold')
    
    ax.set_xlabel('æ™‚é–“ (ç§’)', fontsize=12)
    ax.set_ylabel('æŒ¯å¹…', fontsize=12)
    ax.set_title('éŸ³å£°æ³¢å½¢ã¨ç•°å¸¸æ¤œçŸ¥çµæžœ', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    
    # å‡¡ä¾‹
    from matplotlib.patches import Patch
    legend_elements = [
        Patch(facecolor='lightgreen', alpha=0.5, label='OK (æ­£å¸¸)'),
        Patch(facecolor='lightcoral', alpha=0.5, label='NG (ç•°å¸¸)')
    ]
    ax.legend(handles=legend_elements, loc='upper right')
    
    plt.tight_layout()
    return fig

# ãƒ¡ã‚¤ãƒ³å‡¦ç†
def main():
    st.title("ðŸŽµ éŸ³å£°ç•°å¸¸æ¤œçŸ¥ã‚¢ãƒ—ãƒª")
    st.markdown("**æŒ‡å®šã—ãŸæ™‚é–“ãƒžã‚¤ã‚¯ã§éŒ²éŸ³ã—ã€1ç§’æ¯Žã«OK/NGã‚’åˆ¤å®šã—ã¦æ³¢å½¢ä¸Šã«è¡¨ç¤ºã—ã¾ã™**")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼è¨­å®š
    st.sidebar.header("âš™ï¸ è¨­å®š")
    duration = st.sidebar.slider("éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰", min_value=1, max_value=30, value=5)
    sample_rate = st.sidebar.selectbox("ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°å‘¨æ³¢æ•°", [22050, 44100], index=1)
    
    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    if 'model' not in st.session_state:
        with st.spinner("ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ä¸­..."):
            st.session_state.model = load_model()
    
    st.success("âœ… ãƒ¢ãƒ‡ãƒ«ãŒæº–å‚™å®Œäº†ã—ã¾ã—ãŸï¼")
    
    # éŒ²éŸ³ãƒœã‚¿ãƒ³
    col1, col2 = st.columns([1, 1])
    
    with col1:
        if st.button("ðŸŽ¤ éŒ²éŸ³é–‹å§‹", type="primary"):
            # éŒ²éŸ³å®Ÿè¡Œ
            audio_data = record_audio(duration, sample_rate)
            
            if audio_data is not None:
                st.success("âœ… éŒ²éŸ³å®Œäº†ï¼")
                
                # éŸ³å£°åˆ†æž
                with st.spinner("éŸ³å£°ã‚’åˆ†æžä¸­..."):
                    segments, predictions, confidences = analyze_audio(
                        audio_data, st.session_state.model, sample_rate
                    )
                
                # çµæžœã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã«ä¿å­˜
                st.session_state.audio_data = audio_data
                st.session_state.predictions = predictions
                st.session_state.confidences = confidences
                st.session_state.sample_rate = sample_rate
    
    with col2:
        if st.button("ðŸ”„ ãƒªã‚»ãƒƒãƒˆ"):
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚’ã‚¯ãƒªã‚¢
            for key in ['audio_data', 'predictions', 'confidences']:
                if key in st.session_state:
                    del st.session_state[key]
            st.success("ãƒªã‚»ãƒƒãƒˆã—ã¾ã—ãŸ")
    
    # çµæžœè¡¨ç¤º
    if 'audio_data' in st.session_state and 'predictions' in st.session_state:
        st.header("ðŸ“Š çµæžœ")
        
        # çµ±è¨ˆæƒ…å ±
        predictions = st.session_state.predictions
        ok_count = predictions.count(0)
        ng_count = predictions.count(1)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ç·æ™‚é–“", f"{len(predictions)}ç§’")
        with col2:
            st.metric("OKï¼ˆæ­£å¸¸ï¼‰", f"{ok_count} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ", delta=None)
        with col3:
            st.metric("NGï¼ˆç•°å¸¸ï¼‰", f"{ng_count} ã‚»ã‚°ãƒ¡ãƒ³ãƒˆ", delta=None)
        
        # æ³¢å½¢ã‚°ãƒ©ãƒ•
        fig = plot_results(st.session_state.audio_data, predictions, st.session_state.sample_rate)
        st.pyplot(fig)
        
        # è©³ç´°çµæžœ
        with st.expander("ðŸ“‹ è©³ç´°çµæžœ"):
            for i, (pred, conf) in enumerate(zip(predictions, st.session_state.confidences)):
                status = "âœ… OK" if pred == 0 else "âŒ NG"
                st.write(f"{i+1}ç§’ç›®: {status} (ä¿¡é ¼åº¦: {conf:.3f})")
    
    # èª¬æ˜Ž
    st.markdown("---")
    st.markdown("### ðŸ“– ä½¿ã„æ–¹")
    st.markdown("""
    1. **éŒ²éŸ³æ™‚é–“ã‚’è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§éŒ²éŸ³æ™‚é–“ï¼ˆ1-30ç§’ï¼‰ã‚’é¸æŠž
    2. **éŒ²éŸ³é–‹å§‹**: ã€ŒðŸŽ¤ éŒ²éŸ³é–‹å§‹ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ã¦ãƒžã‚¤ã‚¯ã«å‘ã‹ã£ã¦è©±ã™
    3. **çµæžœç¢ºèª**: æ³¢å½¢ã‚°ãƒ©ãƒ•ã§1ç§’æ¯Žã®OK/NGåˆ¤å®šçµæžœã‚’ç¢ºèª
    4. **ãƒªã‚»ãƒƒãƒˆ**: æ–°ã—ã„éŒ²éŸ³ã‚’è¡Œã†å ´åˆã¯ã€ŒðŸ”„ ãƒªã‚»ãƒƒãƒˆã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™
    
    **åˆ¤å®šã«ã¤ã„ã¦:**
    - ðŸŸ¢ **OKï¼ˆæ­£å¸¸ï¼‰**: æ­£å¸¸ãªéŸ³å£°ã¨åˆ¤å®š
    - ðŸ”´ **NGï¼ˆç•°å¸¸ï¼‰**: ç•°å¸¸ãªéŸ³å£°ã¨åˆ¤å®š
    """)

if __name__ == "__main__":
    main()